<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Finger Counter Final</title>
<style>
/* Use flexbox for simple, performant centering and layout */
html, body { 
    margin: 0; 
    height: 100%; 
    overflow: hidden; 
    background: black; 
    display: flex; 
    justify-content: center;
    align-items: center;
}
  
/* Keep canvas minimal and let JS/flexbox handle sizing */
canvas { 
    display: block; 
    position: absolute; 
    top: 0; 
    left: 0;
    z-index: 50; 
    width: 100%; 
    height: 100%;
}
  
/* No changes to button style */
#fullscreen-btn {
    position: absolute;
    top: 10px;
    right: 10px;
    z-index: 100;
    padding: 10px 20px;
    font-size: 16px;
    background-color: #2ECC71; 
    color: white;
    border: none;
    border-radius: 5px;
    cursor: pointer;
    transition: opacity 0.3s;
    opacity: 1; 
}

.hidden {
    display: none !important;
}
</style>
<link rel="preconnect" href="https://cdn.jsdelivr.net">
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
</head>
<body>
<video id="video" autoplay playsinline style="display:none;"></video>
<canvas id="canvas"></canvas>

<button id="fullscreen-btn">Go Fullscreen</button>

<script>
// --- Core Setup ---

const videoElement = document.getElementById('video');
const canvas = document.getElementById('canvas');
const ctx = canvas.getContext('2d', { alpha: false }); 

const fullscreenBtn = document.getElementById('fullscreen-btn');
let camera = null; 
let totalFingers = 0; 
let handCount = 0;

const tips = [4, 8, 12, 16, 20];
const pips = [3, 6, 10, 14, 18];
const HAND_CONNECTIONS = window.HAND_CONNECTIONS; 

// --- Fullscreen and UI Management ---

function toggleFullscreen() {
    if (!document.fullscreenElement) {
        document.documentElement.requestFullscreen().catch(err => {
            console.error("Fullscreen blocked. User must click to activate.");
            fullscreenBtn.classList.remove('hidden');
        });
    } else if (document.exitFullscreen) {
        document.exitFullscreen();
    }
}

function handleFullscreenChange() {
    if (document.fullscreenElement) {
        fullscreenBtn.classList.add('hidden');
    } else {
        fullscreenBtn.classList.remove('hidden');
    }
    resizeCanvas();
}

fullscreenBtn.addEventListener('click', toggleFullscreen);
document.addEventListener('fullscreenchange', handleFullscreenChange);
document.addEventListener('webkitfullscreenchange', handleFullscreenChange);


function resizeCanvas() {
    const newWidth = window.innerWidth;
    const newHeight = window.innerHeight;

    if (canvas.width !== newWidth || canvas.height !== newHeight) {
        canvas.width = newWidth;
        canvas.height = newHeight;
    }
}

let resizeTimeout;
window.addEventListener('resize', () => {
    clearTimeout(resizeTimeout);
    resizeTimeout = setTimeout(resizeCanvas, 100); 
});

// --- FingerCounter Logic ---

function distance(p1, p2) {
    return Math.hypot(p1.x - p2.x, p1.y - p2.y);
}

function countFingers(lm) {
    const fingersUp = []; 
    const wrist = lm[0];
    
    // Thumb logic
    const thumbTipX = lm[tips[0]].x;
    const thumbPipX = lm[pips[0]].x;
    const thumbMcpX = lm[2].x;
    const wristX = lm[0].x;

    if (thumbMcpX > wristX) {
        fingersUp.push(thumbTipX > thumbPipX ? 1 : 0);
    } else {
        fingersUp.push(thumbTipX < thumbPipX ? 1 : 0);
    }

    // Other 4 fingers
    for (let i = 1; i < 5; i++) {
        const tip = lm[tips[i]];
        const pip = lm[pips[i]];
        
        const tipToWristDist = distance(tip, wrist);
        const pipToWristDist = distance(pip, wrist);

        fingersUp.push(tipToWristDist > pipToWristDist ? 1 : 0);
    }

    return fingersUp.reduce((a, b) => a + b, 0);
}

// --- MediaPipe and Rendering Setup (Using the correct aspect ratio for drawing) ---

const hands = new Hands({
    locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`
});

hands.setOptions({
    maxNumHands: 2, 
    modelComplexity: 0, 
    minDetectionConfidence: 0.6, 
    minTrackingConfidence: 0.4
});

hands.onResults(results => {
    requestAnimationFrame(() => {
        
        ctx.save();
        
        // 1. Clear the canvas with a solid black fill
        ctx.fillStyle = 'black';
        ctx.fillRect(0, 0, canvas.width, canvas.height); 
        
        // --- Aspect Ratio Correction Logic ---
        // Use the video element's intrinsic dimensions (which are now set to the camera's resolution)
        const videoW = videoElement.videoWidth;
        const videoH = videoElement.videoHeight;
        const videoRatio = videoW / videoH;
        const canvasRatio = canvas.width / canvas.height;
        
        let drawWidth, drawHeight, offsetX, offsetY;
        
        // We use the "Contain" strategy here to ensure the whole image is visible
        // (Black bars might appear, but tracking will be accurate as the landmark-to-pixel
        // mapping is now consistent with the displayed image)
        if (videoRatio > canvasRatio) {
            // Video is wider than canvas. Fit to width.
            drawWidth = canvas.width;
            drawHeight = drawWidth / videoRatio;
            offsetX = 0;
            offsetY = (canvas.height - drawHeight) / 2;
        } else {
            // Video is taller than canvas. Fit to height.
            drawHeight = canvas.height;
            drawWidth = drawHeight * videoRatio;
            offsetY = 0;
            offsetX = (canvas.width - drawWidth) / 2;
        }
        // --- End Aspect Ratio Correction Logic ---
        
        // 2. Flip the drawing space (mirrors video and hand landmarks)
        // We only flip the video portion of the canvas.
        ctx.translate(canvas.width, 0);
        ctx.scale(-1, 1);
        
        // 3. Draw the video frame (it will be mirrored, scaled, and centered)
        // Note: The drawing function is flipped, so we adjust the offsetX accordingly.
        const flippedOffsetX = (canvas.width - offsetX) - drawWidth;
        ctx.drawImage(results.image, flippedOffsetX, offsetY, drawWidth, drawHeight); 
        
        totalFingers = 0;
        handCount = 0;
        
        if (results.multiHandLandmarks) {
            handCount = results.multiHandLandmarks.length;
            
            // Set font and color for hand-level count (Green: #00FF00)
            ctx.fillStyle = '#00FF00'; 
            ctx.font = `bold 75px Arial`; 

            for (const landmarks of results.multiHandLandmarks) {
                
                // 4. Draw Hand Visualization (White Lines, Red Points)
                // Landmarking needs to be scaled and offset to match the drawn video frame.
                ctx.save();
                
                // CRITICAL FIX: Scale and translate the drawing context to align with the video.
                const scaleX = drawWidth / videoW;
                const scaleY = drawHeight / videoH;

                // MediaPipe gives normalized coords (0-1). We map these to the scaled/offset video area.
                // We must apply the inverse transform to the drawing context where the video was drawn.
                // We use the full canvas width for the drawing transformation, as we haven't restored yet.

                // Translate the drawing origin to the top-left of the scaled video area
                ctx.translate(canvas.width - offsetX - drawWidth, offsetY); 

                // Scale the drawing context down to the ratio of the video stream to the canvas space.
                ctx.scale(scaleX * (videoW / canvas.width), scaleY * (videoH / canvas.height)); 
                
                drawConnectors(ctx, landmarks, HAND_CONNECTIONS, {color: '#FFFFFF', lineWidth: 4}); 
                drawLandmarks(ctx, landmarks, {color: '#FF0000', lineWidth: 2, radius: 5}); 
                
                // Restore state before drawing text, as the scale/translate messes up text size.
                ctx.restore();
                ctx.save(); // Save again for the text transformation

                const fingers = countFingers(landmarks);
                totalFingers += fingers;

                // 5. Text Position: Center of the palm (Landmark 9)
                // Calculate the final pixel coordinates *after* scaling and offset
                const cx = (landmarks[9].x * drawWidth) + offsetX;
                const cy = (landmarks[9].y * drawHeight) + offsetY;
                
                // CRITICAL FIX: To display the number correctly (un-flipped) on the flipped video area,
                // we apply a temporary anti-flip transformation centered on the text position.
                
                ctx.translate(cx, cy);
                ctx.scale(-1, 1); 
                
                // Draw text at (-30, -30) relative to the palm (Landmark 9)
                ctx.fillText(String(fingers), -30, -30);

                // Restore the state to continue the main loop with the video flip active
                ctx.restore();
            }
        }
        
        // 6. Restore the canvas transform (undo the main video flip)
        ctx.restore(); 
        
        // --- Draw Total Counts (Drawn after restore, in the top-left) ---
        
        // Set font for total count (Blue: #0000FF)
        ctx.fillStyle = '#0000FF'; 
        ctx.font = `bold 30px Arial`; 

        // Requested positions (10, 30) and (10, 70)
        ctx.fillText(`Finger Count: ${totalFingers}`, 10, 30); 
        ctx.fillText(`Hands: ${handCount}`, 10, 70); 

    }); // End requestAnimationFrame
});

// --- Camera Initialization and Program Start (FIX: Dynamic Resolution Setup) ---

const initCamera = async () => {
    // 1. Request the camera stream using constraints that prefer HD resolution
    const stream = await navigator.mediaDevices.getUserMedia({
        video: {
            // Set preferred resolution, allowing the browser to choose the best available
            width: { ideal: 1280, min: 640 },
            height: { ideal: 720, min: 480 },
            facingMode: 'user'
        }
    });
    
    // 2. Attach stream to video element
    videoElement.srcObject = stream;
    
    // Wait for the video stream to load metadata and set its intrinsic size
    await new Promise((resolve) => {
        videoElement.onloadedmetadata = () => {
            // 3. CRITICAL: Set the video element's attributes to the camera's actual resolution
            // This ensures results.image.width/height are correct for the aspect ratio math
            videoElement.width = videoElement.videoWidth;
            videoElement.height = videoElement.videoHeight;
            resolve(true);
        };
    });

    // 4. Initialize MediaPipe Camera utility using the determined dimensions
    camera = new Camera(videoElement, {
        onFrame: async () => {
            await hands.send({image: videoElement});
        },
        // IMPORTANT: We use the actual determined width/height here
        width: videoElement.width, 
        height: videoElement.height,
        mirrored: false
    });
    camera.start();
};

// Initial setup
resizeCanvas();

// Starter function for first click to handle fullscreen/permissions
document.addEventListener('click', function starter() {
    if (!document.fullscreenElement) {
        toggleFullscreen(); 
    }
    // Now call the async camera setup function
    initCamera().catch(e => console.error("Camera initialization failed:", e));
    document.removeEventListener('click', starter);
}, {once: true});

handleFullscreenChange();
</script>
</body>
</html>